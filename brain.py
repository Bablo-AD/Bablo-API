import openai
import os
import tiktoken


class brain_api:
    """
    This class represents the brain API for interacting with the GPT-3.5-turbo model.
    """

    def __init__(self,api_key):
        """
        Initializes the brain API with the OpenAI API key.
        """
        self.api_key = api_key
        self.model = "gpt-3.5-turbo-0613"
        openai.api_key = self.api_key
        
    def get_completion_for_message(self, message, temperature=0):
        """
        Generates a completion for a given message using the GPT-3.5-turbo model.

        Args:
            message (list): List of messages representing the conversation history.
            temperature (float): Control the randomness of the output.

        Returns:
            str: The completion generated by the model.
            int: The number of tokens used by the completion.
        """
        completion = openai.ChatCompletion.create(
            model=self.model,
            messages=message,
            temperature=temperature
        )
        return completion.choices[0].message['content'], completion['usage']['prompt_tokens']
    
    def get_completion(self, message_history, message='', update_history=False, temperature=0):
        """
        Generates a completion for the conversation history.

        Args:
            message_history (message_history): The conversation history.
            message (str): The user's message to be added to the history.
            update_history (bool): Flag to update the conversation history.
            temperature (float): Control the randomness of the output.

        Returns:
            str: The completion generated by the model.
            int: The number of tokens used by the completion.
        """
        if message == '':
            completion_output = self.get_completion_for_message(message_history.messages, temperature)
            if update_history:
                message_history.add_assistant(completion_output[0])
                message_history.tokens = completion_output[1]
                return message_history.get_last_message()['content'], message_history.tokens
            else:
                return completion_output
        else:
            if update_history:
                message_history.add_user(message)
                completion_output = self.get_completion_for_message(message_history.messages, temperature)
                message_history.add_assistant(completion_output[0])
                message_history.tokens = completion_output[1]
                return message_history.get_last_message()['content'], message_history.tokens
            else:
                temporary_message = message_history.messages.copy()
                temporary_message.append({"role": "user", "content": message})
                completion_output = self.get_completion_for_message(temporary_message, temperature)
                return completion_output
    
    def converse(self, message_history, update_history=False, temperature=0):
        """
        Starts a conversation with the model.

        Args:
            message_history (message_history): The conversation history.
            update_history (bool): Flag to update the conversation history.
            temperature (float): Control the randomness of the output.
        """
        print(self.get_completion(message_history=message_history, update_history=update_history, temperature=temperature))
        while True:
            user_input = input()
            if user_input == '\\break':
                return message_history
            print(self.get_completion(message_history=message_history, message=user_input, update_history=update_history, temperature=temperature))

class message_history_base:
    """
    This class represents the message history for a conversation.
    """

    def __init__(self):
       
        #Initializes the message history.
        self.messages = []
        self.tokens = 0
    
    def add(self, role, content):
        """
        Adds a message to the message history.

        Args:
            role (str): The role of the message (user, assistant, etc.).
            content (str): The content of the message.
        """
        self.messages.append({"role": role, "content": content})
    
    def add_user(self, content):
        """
        Adds a user message to the message history.

        Args:
            content (str): The content of the user message.
        """
        self.messages.append({"role": "user", "content": content})
    
    def add_assistant(self, content):
        """
        Adds an assistant message to the message history.

        Args:
            content (str): The content of the assistant message.
        """
        self.messages.append({"role": "assistant", "content": content})
    
    def add_system(self, content):
        """
        Adds a system message to the message history.

        Args:
            content (str): The content of the system message.
        """
        self.messages.append({"role": "system", "content": content})
    
    def append(self, content_list):
        """
        Appends a list of messages to the message history.

        Args:
            content_list (list): List of messages to be appended.
        """
        self.messages.extend(content_list)
    
    def get_last_message(self):
        """
        Returns the last message in the message history.

        Returns:
            dict: The last message in the message history.
        """
        return self.messages[-1]
    
    def get_token_estimate(self, message='', model="gpt-3.5-turbo-0301"):
        """
        Estimates the number of tokens used by the messages.

        Args:
            message (str): Optional message for token estimation.
            model (str): Model name for token estimation.

        Returns:
            int: The estimated number of tokens.
        """
        if message == '':
            message = self.messages
        try:
            encoding = tiktoken.encoding_for_model(model)
        except KeyError:
            encoding = tiktoken.get_encoding("cl100k_base")
        if model == "gpt-3.5-turbo-0301":
            num_tokens = 0
            for message in message:
                num_tokens += 4
                for key, value in message.items():
                    num_tokens += len(encoding.encode(value))
                    if key == "name":
                        num_tokens += -1
            num_tokens += 2
            if message == self.messages:
                self.estimated_tokens = num_tokens
            return num_tokens
        else:
            raise NotImplementedError(f"""num_tokens_from_messages() is not presently implemented for model {model}.
        See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.""")

class message_history(message_history_base):
    def load_mentorship(self,journal_data,habitica_data,phone_usage_data,TODAY,PAST_HISTORY):
        self.add_system(f"Now you are the user's partner who criticizes the user and helps him grow. Here I provide you the details of the user from the past {PAST_HISTORY} days till {TODAY}.")

        if habitica_data != '':
            self.add_system(f"User's habits: {habitica_data}")
        if journal_data != '':
            self.add_system(f"User's journal: {journal_data}")
        if phone_usage_data != '':
            self.add_system(f"User's Phone Usage: {phone_usage_data}")
        
    def load_query(self,goal=''):
        if goal == '':
            self.add_system('Hey the user would like to watch youtube can you give me a search query that makes improves or makes the users life better from what you have read from the user journals')
        else:
            self.add_system(f'Hey the user would like to watch youtube can you give the user a search query for {goal} optimised to the user journal')
    def load_python_fear(self):
        self.add_user('Hey i will be passing the output through a python script to get the information so i need them ordered')